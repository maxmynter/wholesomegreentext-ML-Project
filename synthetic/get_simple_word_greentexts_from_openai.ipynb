{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGreentexts on 4chan cover a wide range of topics, reflecting the diverse interests and experiences of its user base.\\nSome of them follow the following pattern and end in a thank you\\n\\n{{\"0\": \"> Wake up late\\n> Realize it\\'s weekend\\n> No alarms\\n> Feeling bliss\\n> Thank you weekend\",\\n  \"1\": \"> Go for a walk\\n> See a random dog\\n> Dog wags tail\\n> Best friends for 5 minutes\\n> Thank you random dog\",\\n  \"2\": \"> Have a tough day\\n> Find a forgotten chocolate bar in my bag\\n> Suddenly not so bad\\n> Thank you chocolate bar\"}}\\n\\nThe stories are for adult language learners. Therefore, use only vocabulary a 3-4 year old native speaker can understand.\\n Your generation should be of the theme: Memes and Internet Humor: Stories that reference popular memes, internet jokes, or trends.\\nGenerate a json with 25 original examples that end with a thank you by the narrator to the object of the story. Produce a valid json string. Use only single-quotes inside the object values. Answer only with the json object.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chanStyleTypes = [\n",
    "    \"Personal Anecdotes: Stories about users' personal experiences, often with unexpected twists or humorous conclusions.\",\n",
    "    \"Historical and Cultural References: Stories that play on historical events, cultural phenomena, or popular media, often with an ironic or satirical twist.\",\n",
    "    \"Fantasy and Sci-Fi: Tales involving elements from fantasy or science fiction, such as time travel, mythical creatures, or futuristic scenarios.\",\n",
    "    \"Everyday Observations: Relatable incidents or observations from daily life, presented in a humorous or exaggerated manner.\",\n",
    "    \"Work and School Experiences: Stories about interesting, funny, or bizarre occurrences in professional or educational settings.\",\n",
    "    \"Relationships and Social Interactions: Accounts of romantic endeavors, friendships, family dynamics, and awkward social situations.\",\n",
    "    \"Memes and Internet Humor: Stories that reference popular memes, internet jokes, or trends.\",\n",
    "    \"Internet and Technology: Anecdotes about experiences with technology, internet culture, and digital interactions.\",\n",
    "    \"Philosophical and Pseudo-Intellectual Musings: Abstract, often humorous musings on life, existence, and philosophical concepts.\",\n",
    "    \"Parody and Satire: Stories that mock or satirize various aspects of society, politics, celebrity culture, etc.\",\n",
    "    \"Adventure and Exploration: Imaginary or exaggerated tales of adventure, exploration, or extraordinary experiences.\",\n",
    "    \"Role Reversal and Perspective Shifts: Stories told from unconventional perspectives or featuring surprising role reversals.\"\n",
    "]\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Greentexts on 4chan cover a wide range of topics, reflecting the diverse interests and experiences of its user base.\n",
    "Some of them follow the following pattern and end in a thank you\n",
    "\n",
    "{{\"0\": \"> Wake up late\\n> Realize it's weekend\\n> No alarms\\n> Feeling bliss\\n> Thank you weekend\",\n",
    "  \"1\": \"> Go for a walk\\n> See a random dog\\n> Dog wags tail\\n> Best friends for 5 minutes\\n> Thank you random dog\",\n",
    "  \"2\": \"> Have a tough day\\n> Find a forgotten chocolate bar in my bag\\n> Suddenly not so bad\\n> Thank you chocolate bar\"}}\n",
    "\n",
    "The stories are for adult language learners. Therefore, use only vocabulary a 3-4 year old native speaker can understand.\n",
    "\"\"\"\n",
    "def generate_prompt():\n",
    "    prompt = f\"\"\"{system_prompt} Your generation should be of the theme: {chanStyleTypes[np.random.randint(len(chanStyleTypes))]}\\nGenerate a json with 25 original examples that end with a thank you by the narrator to the object of the story. Produce a valid json string. Use only single-quotes inside the object values. Answer only with the json object.\"\"\"\n",
    "    return prompt\n",
    "generate_prompt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_filename(length=12, extension=\".json\"):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for _ in range(length)) + extension\n",
    "\n",
    "def save_string_to_json(content, directory):\n",
    "    filename = generate_random_filename()\n",
    "    with open(os.path.join(directory, filename), 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_openai_json_format(json_string):\n",
    "    parsed_json_string = json_string.replace(\"{\\n\", \"{\").replace(\"{ \\n\",\"{\").replace(\",\\n\",\",\").replace('\"\\n\"','\",\"').replace(\"\\n}\",\"}\").replace(\"\\n }\",\"}\").replace(\"}\\n\",\"}\").replace(\",}\", \"}\").replace(\"\\n\", \"\\\\n\")\n",
    "    return parsed_json_string\n",
    "\n",
    "def make_openai_request(api_key, prompt):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\")\n",
    "    return handle_openai_json_format(response.choices[0].message.content)\n",
    "\n",
    "def save_openai_response_to_file(response, directory):\n",
    "    save_string_to_json(response, directory=directory)\n",
    "\n",
    "def make_and_save_request(api_key, prompt, output_directory=\"./thanks_output/\"):\n",
    "    response = make_openai_request(api_key, prompt)\n",
    "    save_openai_response_to_file(response, directory=f\"{output_directory}/\")\n",
    "\n",
    "def get_openai_data(api_key, num_requests=2):\n",
    "    prompts = [generate_prompt() for _ in range(num_requests)]\n",
    "\n",
    "    Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(make_and_save_request)(api_key, prompt) for prompt in prompts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed: 46.9min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 54.8min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 60.6min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed: 66.4min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 69.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed: 72.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1089 tasks      | elapsed: 75.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 78.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1185 tasks      | elapsed: 81.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1285 tasks      | elapsed: 88.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1336 tasks      | elapsed: 91.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1389 tasks      | elapsed: 94.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 98.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1497 tasks      | elapsed: 102.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed: 105.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1609 tasks      | elapsed: 109.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1666 tasks      | elapsed: 113.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1725 tasks      | elapsed: 116.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 120.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1845 tasks      | elapsed: 125.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1906 tasks      | elapsed: 129.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 133.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed: 137.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2097 tasks      | elapsed: 142.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 146.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2229 tasks      | elapsed: 151.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2296 tasks      | elapsed: 155.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2365 tasks      | elapsed: 160.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 165.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed: 169.5min finished\n"
     ]
    }
   ],
   "source": [
    "get_openai_data(openai_api_key, num_requests=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wholesomegreentextllm-RqUaalAq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
